### Big O

Big-O notation is a form of measuring the complexity of an algorithm in the worst-case scenario. The analysis can be made for time or memory space complexity. What is interesting is to see how the runtime or space requirements changes when the input size increases. 

##### Runtime Examples
